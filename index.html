
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<script src="bootstrap.js"></script>
<script type="text/javascript" charset="utf-8" src="https://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script> 
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<style type="text/css">
body {
    font-family: "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight: 300;
    font-size: 17px;
    margin-left: auto;
    margin-right: auto;
}

@media screen and (min-width: 980px){
    body {
        width: 980px;
    }
}

h1 {
    font-weight:300;
    line-height: 1.15em;
}

h2 {
    font-size: 1.75em;
}
a:link,a:visited {
    color: #5364cc;
    text-decoration: none;
}
a:hover {
    color: #208799;
}
h1 {
    text-align: center;
}
h2,h3 {
    text-align: left;
}

h1 {
    font-size: 40px;
    font-weight: 500;
}
h2 {
    font-weight: 400;
    margin: 16px 0px 4px 0px;
}
h3 {
    font-weight: 600;
    margin: 16px 0px 4px 0px;
}

.paper-title {
    padding: 1px 0px 1px 0px;
}
section {
    margin: 32px 0px 32px 0px;
    text-align: justify;
    clear: both;
}
.col-5 {
     width: 20%;
     float: left;
}
.col-4 {
     width: 25%;
     float: left;
}
.col-3 {
     width: 33%;
     float: left;
}
.col-2 {
     width: 50%;
     float: left;
}
.col-1 {
     width: 100%;
     float: left;
}

.author-row, .affil-row {
    font-size: 26px;
}

.author-row-new { 
    text-align: center; 
}

.author-row-new a {
    display: inline-block;
    font-size: 20px;
    padding: 4px;
}

.author-row-new sup {
    color: #313436;
    font-size: 12px;
}

.affiliations-new {
    font-size: 18px;
    text-align: center;
    width: 80%;
    margin: 0 auto;
    margin-bottom: 20px;
}

.row {
    margin: 16px 0px 16px 0px;
}
.authors {
    font-size: 26px;
}
.affiliatons {
    font-size: 18px;
}
.affil-row {
    margin-top: 18px;
}
.teaser {
    max-width: 100%;
}
.text-center {
    text-align: center;  
}
.screenshot {
    width: 256px;
    border: 1px solid #ddd;
}
.screenshot-el {
    margin-bottom: 16px;
}
hr {
    height: 1px;
    border: 0; 
    border-top: 1px solid #ddd;
    margin: 0;
}
.material-icons {
    vertical-align: -6px;
}
p {
    line-height: 1.25em;
}
.caption {
    font-size: 16px;
    color: #666;
    margin-top: 4px;
    margin-bottom: 10px;
}


video {
    display: block;
    margin: auto;
}


figure {
    display: block;
    margin: auto;
    margin-top: 10px;
    margin-bottom: 10px;
}
#bibtex pre {
    font-size: 14px;
    background-color: #eee;
    padding: 16px;
}
.blue {
    color: #2c82c9;
    font-weight: bold;
}
.orange {
    color: #d35400;
    font-weight: bold;
}
.flex-row {
    display: flex;
    flex-flow: row wrap;
    padding: 0;
    margin: 0;
    list-style: none;
}

.paper-btn-coming-soon {
    position: relative; 
    top: 0;
    left: 0;
}

.coming-soon {
    position: absolute;
    top: -15px;
    right: -15px;
}

.paper-btn {
  position: relative;
  text-align: center;

  display: inline-block;
  margin: 8px;
  padding: 8px 8px;

  border-width: 0;
  outline: none;
  border-radius: 2px;
  
  background-color: #5364cc;
  color: white !important;
  font-size: 20px;
  width: 100px;
  font-weight: 600;
}
.paper-btn-parent {
    display: flex;
    justify-content: center;
    margin: 16px 0px;
}

.paper-btn:hover {
    opacity: 0.85;
}

.container {
    margin-left: auto;
    margin-right: auto;
    padding-left: 16px;
    padding-right: 16px;
}

.venue {
    font-size: 23px;
}

.topnav {
    background-color: #EEEEEE;
    overflow: hidden;
}

.topnav div {
    max-width: 1070px;
    margin: 0 auto;
}

.topnav a {
    display: inline-block;
    color: black;
    text-align: center;
    vertical-align: middle;
    padding: 16px 16px;
    text-decoration: none;
    font-size: 18px;
}

.topnav img {
    padding: 2px 0px;
    width: 100%;
    margin: 0.2em 0px 0.3em 0px;
    vertical-align: middle;
}

pre {
    font-size: 0.9em;
    padding-left: 7px;
    padding-right: 7px;
    padding-top: 3px;
    padding-bottom: 3px;
    border-radius: 3px;
    background-color: rgb(235, 235, 235);
    overflow-x: auto;
}

.download-thumb {
    display: flex;
}

@media only screen and (max-width: 620px) {
    .download-thumb {
        display: none;
    }
}

.paper-stuff {
    width: 50%;
    font-size: 20px;
}

@media only screen and (max-width: 620px) {
    .paper-stuff {
        width: 100%;
    }
}
* {
  box-sizing: border-box;
}

.column {
  text-align: center;
  float: left;
  width: 16.666%;
  padding: 5px;
}
.column3 {
  text-align: center;
  float: left;
  width: 33.333%;
  padding: 5px;
}
.column4 {
  text-align: center;
  float: left;
  width: 50%;
  padding: 5px;
}
.column5 {
  text-align: center;
  float: left;
  width: 20%;
  padding: 5px;
}
.border-right {
    border-right: 1px solid black;
}
.border-bottom{
    border-bottom: 1px solid black;
}



/* Clearfix (clear floats) */
.row::after {
  content: "";
  clear: both;
  display: table;
}
.img-fluid {
  max-width: 100%;
  height: auto;
}
.figure-img {
  margin-bottom: 0.5rem;
  line-height: 1;
}








.rounded-circle {
  border-radius: 50% !important;
}






/* Responsive layout - makes the three columns stack on top of each other instead of next to each other */
@media screen and (max-width: 500px) {
  .column {
    width: 100%;
  }
}
@media screen and (max-width: 500px) {
  .column3 {
    width: 100%;
  }
}

</style>
<link rel="stylesheet" href="bootstrap-grid.css">

<script type="text/javascript" src="../js/hidebib.js"></script>
    <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
    <head>
        <title> DiffMesh: A Motion-aware Diffusion-like Framework for Human Mesh Recovery from Videos</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta property="og:description" content="DiffMesh: A Motion-aware Diffusion-like Framework for Human Mesh Recovery from Videos"/>
        <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">
        <meta name="twitter:title" content="DiffMesh: A Motion-aware Diffusion-like Framework for Human Mesh Recovery from Videos">
        <meta name="twitter:description" content="">
        <meta name="twitter:image" content="">
    </head>

 <body>


<div class="container">
    <div class="paper-title">
    <h1> 
        DiffMesh: A Motion-aware Diffusion-like Framework for Human Mesh Recovery from Videos
    </div>

    <div id="authors">
        <center>
            <div class="author-row-new">
                <a href="https://zczcwh.github.io/">Ce Zheng<sup>1</sup></a>,
                <a href="https://xianpeng919.github.io/">Xianpeng Liu<sup>2</sup></a>,
                <a href="https://robotics.pkusz.edu.cn/">Mengyuan Liu<sup>2</sup></a>,
                <a href="https://tfwu.github.io/">Tianfu Wu<sup>2</sup></a>,
                <a href="http://maple-lab.net/gqi/">Guo-Jun Qi<sup>4,5</sup></a>,
                <a href="https://www.crcv.ucf.edu/chenchen/">Chen Chen<sup>1</sup></a>,
            </div>
        </center>
        <center>
        <div class="affiliations">
            <span><sup>1</sup> Center for Research in Computer Vision, University of Central Florida </span><br/>
            <span><sup>2</sup> North Carolina State University </span><br/>
            <span><sup>3</sup> Key Laboratory of Machine Perception, Peking University, Shenzhen Graduate School </span><br/>
            <span><sup>4</sup> OPPO Seattle Research Center, USA </span><br/>
            <span><sup>5</sup> Westlake University </span><br/>
        </div>

<!--         <br>*indicates equal contribution. -->

        <div class="affil-row">
            <div class="venue text-center"><b> arXiv 2023 </b></div>
        </div>

        </center>

        <div style="clear: both">
            <div class="paper-btn-parent">
            <a class="paper-btn" href="">
                <span class="material-icons"> description </span> 
                 Paper
            </a>
            <a class="paper-btn" href="https://github.com/zczcwh/DiffMesh">
                <span class="material-icons"> code </span>
                Code
            </a>
            <a class="paper-btn" href="">
                <span class="material-icons"> code </span>
                Video
            </a>  
        </div>
    </div>

    
   
        
<!--     </section>
    <section id="teaser-image">
        <hr>
            <div class="mx-auto">
                <center><img class="card-img-top" src="materials/potter.gif" style="width:350px"></center>
            </div>
        <hr> -->
    
    

    
    <section id="abstract"/>
        <hr>
        <h2>Abstract</h2>
        <div class="flex-row">
            <p>
                Human mesh recovery (HMR) provides rich human body information for various real-world applications such as gaming, human-computer interaction, and virtual reality. 
                While image-based HMR methods have achieved impressive results, they often struggle to recover humans in dynamic scenarios, leading to temporal inconsistencies and non-smooth 3D motion predictions due to the absence of human motion. 
                In contrast, video-based approaches leverage temporal information to mitigate this issue. In this paper, we present DiffMesh, an innovative motion-aware Diffusion-like framework for video-based HMR. 
                DiffMesh establishes a bridge between diffusion models and human motion, efficiently generating accurate and smooth output mesh sequences by incorporating human motion within the forward process and reverse process in the diffusion model. 
                Extensive experiments are conducted on the widely used datasets, which demonstrate the effectiveness and efficiency of our DiffMesh. Visual comparisons in real-world scenarios further highlight DiffMesh's suitability for practical applications.            </p>
        </div>
    </section>
    <section id="method"/>
        <hr>
        <h2>DiffMesh</h2>

            <br><br>

            <div class="mx-auto">

    </section>
        

<!--     <section id="results">
        <hr>
        <h2>Results of image classification task </h2>
            <br><br>
            <div class="mx-auto">
                <center><img class="card-img-top" src="materials/table_img.jpg" style="width:950px"></center>
            </div>
        <hr>

        <h2>Results of human mesh recovery</h2>
            <br><br>
            <div class="mx-auto">
                <center><img class="card-img-top" src="materials/table_hmr.jpg" style="width:950px"></center>
                 <br><br>
                <center><img class="card-img-top" src="materials/MG_PA.jpg" style="width:550px"></center>
            </div>
        <hr>

        <h2>Mesh visualization</h2>
            <br><br>
            <div class="mx-auto">
                <center><p><b>Frame-by-frame reconstruction for the video input</b></p></center>
                <center><img class="card-img-top" src="materials/supp_vis_video.jpg" style="width:100%"></center>
            </div>
            <br><br>
            <div class="mx-auto">
                <center><p><b>Qualitative comparison with SOTA method METRO</b></p></center>
                <center><img class="card-img-top" src="materials/supp_vis_comp.jpg" style="width:100%"></center>
            </div>
            <br><br>
            <div class="mx-auto">
                <center><p><b>Hand mesh visualization</b></p></center>
                <center><img class="card-img-top" src="materials/supp_vis_hand.jpg" style="width:100%"></center>
            </div>
            <br><br><br>
        <hr>

    </section>

    <section id="paper">
        <h2> Video </h2>
    <div class="video-container">
        <iframe width="896" height="504" src="https://www.youtube.com/embed/-O4V-yqJmms" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
    </div></br>     -->
   
<!--     <section id="paper">
        <h2>Bibtex</h2>
        <div class="page-body"><pre id="ad6975be-3353-467d-ae48-6313d767ffa6" class="code"><code>
            @InProceedings{zheng2023potter,
                title={POTTER: Pooling Attention Transformer for Efficient Human Mesh Recovery},
                author={Zheng, Ce and Liu, Xianpeng and Qi, Guo-Jun and Chen, Chen},
                booktitle ={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
                year={2023}
            }
        </code></pre><p id="1a3aa306-c4b8-4872-8fb0-411495c73d55" class="">
        </p></div>

    </section> -->


    <section>
        This webpage template was adapted from <a href='https://nv-tlabs.github.io/LION/'>here</a>.
    </section>
    


</div>
</body>
</html>
